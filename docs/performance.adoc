= Performance

Tackler is quite fast, it can process one million (1E6) transactions under 20 seconds
and can reach processing speed of over 56 000 transactions per second.  Full Tackler performance tests
results and information of used hardware is link:../perf/results/readme.adoc[located here].

Tackler is also it's 3-20 times faster and it's more memory efficient than
link:./perf-others.adoc[other similar systems].

== Test data

Performance testing is done with artificial transaction data
which mimics real journal. Test data is generated with
link:../tools/generator[generator], which can also generate ledger-like compatible journal formats.

Tests are done with all  report and format types. Account validation is turned on, (e.g. `accounts.strict=true`).
This means that for each transaction it is checked that all txn's accounts are listed in
Chart of Accounts.

The Balance report is used with comparision of other system, because it's semantic is same between
ledger-cli, hledger and abandon.

Each transaction is located on own file, and shard of files is based on txn dates
(e.g. `perf-1E6/YYYY/MM/DD/YYYYMMDDTHHMMSS-idx.txn`, where `idx` is index of txn).

Typical test sets (small and big) are:

 * 1E3 (1000) transactions
 * 1E6 (1 000 000) transactions

Other sets are 1E4 and 1E5.

If tested system doesn't support sharded data, then single file journal file is used.


=== Chart of Accounts for perf tests

Chart of Accounts has 378 entries and it is generated based on txn's dates:

For "assets" following structure is used `a:ay<year>:am<month>`.

This yields to 12 different accounts:

 ...
 "a:ay2016:am01",
 "a:ay2016:am02",
 "a:ay2016:am03",
 ...


For "expenses" following structure is used `e:ey<year>:em<month>:ed<day>`.

This yields to 366 different accounts:

 ...
 "e:ey2016:em01:ed01",
 "e:ey2016:em01:ed02",
 "e:ey2016:em01:ed03",
 ...


== Single file or single input String

With single file Tackler has basically same processing time than with
shard txn data.

However, with 1E6 txns in single input file or in one single string (about 73MB),
Tackler has non-optimal memory usage behaviour, and it's memory usage peaks around 6-7GB.

To work around this, do not put one million (1E6) transactions in single input.
Instead this should be shard data set, e.g. ten files of hundred thousand transactions on each.

Shard data set could be even structured so that there one or only few txn per file.
This is basic mode for performance test, and this setup has basically same processing
time than putting them in one big file (with fast SSD and good disk cache).


==== Single file performance

Tacklers processing time with single file (1E6) is around ~30sec, and memory usage peaks around 6-7G.
Single file performance testing is not part of routine performance testing.
